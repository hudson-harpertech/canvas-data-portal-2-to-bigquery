{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error running command 'snapshot --table access_tokens --format parquet': \n",
      "No parquet files found for job None.\n",
      "Error running command 'snapshot --table account_users --format parquet': \n",
      "No parquet files found for job None.\n",
      "Error running command 'snapshot --table accounts --format parquet': \n",
      "No parquet files found for job None.\n",
      "Error running command 'snapshot --table assessment_question_banks --format parquet': \n",
      "No parquet files found for job None.\n",
      "Error running command 'snapshot --table assessment_questions --format parquet': \n",
      "No parquet files found for job None.\n",
      "Error running command 'snapshot --table assignment_groups --format parquet': \n",
      "No parquet files found for job None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/hudson/Desktop/CanvasData/main.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=129'>130</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo tables found.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=132'>133</a>\u001b[0m     \u001b[39m# Download table data\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m     download_table_data(table)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m     job_id \u001b[39m=\u001b[39m get_job_id()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m     \u001b[39m# Find the downloaded parquet file\u001b[39;00m\n",
      "\u001b[1;32m/home/hudson/Desktop/CanvasData/main.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdownload_table_data\u001b[39m(table_name):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m run_dap_command(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msnapshot --table \u001b[39;49m\u001b[39m{\u001b[39;49;00mtable_name\u001b[39m}\u001b[39;49;00m\u001b[39m --format parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/hudson/Desktop/CanvasData/main.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     client_id \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mus-east-1#af30f4c1-f587-4acc-a0a7-52f4b249207d\u001b[39m\u001b[39m\"\u001b[39m            \u001b[39m# Replace with your actual client ID\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     client_secret \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m3j2eyjXK_riAvNh9TkPZTTCoMlHMmpOpz5d0rE7hzFs\u001b[39m\u001b[39m\"\u001b[39m    \u001b[39m# Replace with your actual client secret\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     result \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdap --base-url \u001b[39;49m\u001b[39m{\u001b[39;49;00mbase_url\u001b[39m}\u001b[39;49;00m\u001b[39m --client-id \u001b[39;49m\u001b[39m{\u001b[39;49;00mclient_id\u001b[39m}\u001b[39;49;00m\u001b[39m --client-secret \u001b[39;49m\u001b[39m{\u001b[39;49;00mclient_secret\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m{\u001b[39;49;00mcommand\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                             check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, shell\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, text\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, capture_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mstdout\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/hudson/Desktop/CanvasData/main.ipynb#W0sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    504\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 505\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    506\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    507\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicate(\u001b[39minput\u001b[39;49m, endtime, timeout)\n\u001b[1;32m   1155\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[39m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(  \u001b[39m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfailed to raise TimeoutExpired.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m   2022\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[39m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[39m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "from google.cloud import bigquery\n",
    "\n",
    "def run_dap_command(command, namespace=\"canvas\"):\n",
    "    try:\n",
    "        base_url = \"https://api-gateway.instructure.com\"  # Replace with your actual base URL\n",
    "        client_id = \"us-east-1#af30f4c1-f587-4acc-a0a7-52f4b249207d\"            # Replace with your actual client ID\n",
    "        client_secret = \"3j2eyjXK_riAvNh9TkPZTTCoMlHMmpOpz5d0rE7hzFs\"    # Replace with your actual client secret\n",
    "\n",
    "        result = subprocess.run(f\"dap --base-url {base_url} --client-id {client_id} --client-secret {client_secret} {command} --namespace {namespace}\", \n",
    "                                check=True, shell=True, text=True, capture_output=True)\n",
    "        return result.stdout\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running command '{command}': {e.output}\")\n",
    "        return None\n",
    "\n",
    "def list_tables():\n",
    "    return run_dap_command(\"list\").split()\n",
    "\n",
    "def download_table_data(table_name):\n",
    "    return run_dap_command(f\"snapshot --table {table_name} --format parquet\")\n",
    "\n",
    "def download_incremental_table_data(table_name, since_datetime):\n",
    "    return run_dap_command(f\"incremental --table {table_name} --format parquet --since {since_datetime}\")\n",
    "\n",
    "def download_table_schema(table_name):\n",
    "    return run_dap_command(f\"schema --table {table_name}\")\n",
    "\n",
    "def get_job_id():\n",
    "    dirs = next(os.walk('downloads'))[1]\n",
    "    if dirs:\n",
    "        return dirs[0]  # Assuming the latest directory is the relevant one\n",
    "    return None\n",
    "\n",
    "def load_json_schema(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def schema_field_to_dict(field):\n",
    "    # Convert a SchemaField to a dictionary\n",
    "    result = {\n",
    "        \"name\": field.name,\n",
    "        \"type\": field.field_type,\n",
    "        \"mode\": field.mode,\n",
    "        \"description\": field.description,\n",
    "    }\n",
    "    if field.field_type == 'RECORD':\n",
    "        result[\"fields\"] = [schema_field_to_dict(f) for f in field.fields]\n",
    "    return result\n",
    "\n",
    "def update_schema_description(bq_schema_fields, json_schema):\n",
    "    updated_fields = []\n",
    "    max_description_length = 1024\n",
    "\n",
    "    for field in bq_schema_fields:\n",
    "        json_field = json_schema.get('properties', {}).get(field.name)\n",
    "        description = field.description\n",
    "\n",
    "        if json_field:\n",
    "            if 'description' in json_field:\n",
    "                # Truncate the description if it's too long\n",
    "                description = json_field['description'][:max_description_length]\n",
    "\n",
    "            if field.field_type == 'RECORD':\n",
    "                nested_fields = update_schema_description(field.fields, json_field) if field.fields else []\n",
    "                new_field = bigquery.SchemaField(\n",
    "                    name=field.name,\n",
    "                    field_type=field.field_type,\n",
    "                    mode=field.mode,\n",
    "                    description=description,\n",
    "                    fields=nested_fields\n",
    "                )\n",
    "            else:\n",
    "                new_field = bigquery.SchemaField(\n",
    "                    name=field.name,\n",
    "                    field_type=field.field_type,\n",
    "                    mode=field.mode,\n",
    "                    description=description\n",
    "                )\n",
    "        else:\n",
    "            # If json_field is None, use the original field\n",
    "            new_field = field\n",
    "\n",
    "        updated_fields.append(new_field)\n",
    "\n",
    "    return updated_fields\n",
    "\n",
    "\n",
    "def update_bigquery_schema_from_json(client, table_id, json_schema_file):\n",
    "    # Load JSON schema\n",
    "    json_schema = load_json_schema(json_schema_file)\n",
    "\n",
    "    # Retrieve the current schema from BigQuery\n",
    "    table = client.get_table(table_id)\n",
    "    bq_schema = table.schema\n",
    "\n",
    "    # Update the schema descriptions\n",
    "    updated_schema = update_schema_description(bq_schema, json_schema['schema'])\n",
    "\n",
    "    # Update the table with the new schema\n",
    "    table.schema = updated_schema\n",
    "    client.update_table(table, ['schema'])\n",
    "\n",
    "def get_latest_schema_file(table_name, directory=\"downloads\"):\n",
    "    schema_file_pattern = re.compile(rf\"{table_name}_schema_version_(\\d+)\\.json\")\n",
    "    highest_version = 0\n",
    "    latest_schema_file = None\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        match = schema_file_pattern.match(file)\n",
    "        if match:\n",
    "            version = int(match.group(1))\n",
    "            if version > highest_version:\n",
    "                highest_version = version\n",
    "                latest_schema_file = file\n",
    "\n",
    "    return os.path.join(directory, latest_schema_file) if latest_schema_file else None\n",
    "\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# List tables\n",
    "tables = list_tables()\n",
    "if not tables:\n",
    "    print(\"No tables found.\")\n",
    "\n",
    "for table in tables:\n",
    "    # Download table data\n",
    "    download_table_data(table)\n",
    "\n",
    "    job_id = get_job_id()\n",
    "\n",
    "    # Find the downloaded parquet file\n",
    "    parquet_files = glob.glob(f'downloads/{job_id}/*.parquet')\n",
    "    if not parquet_files:\n",
    "        print(f\"No parquet files found for job {job_id}.\")\n",
    "        continue\n",
    "    parquet_file = parquet_files[0]\n",
    "\n",
    "    table_ref = client.dataset('CanvasDataPortal2').table(table)\n",
    "\n",
    "    # Load parquet file into BigQuery\n",
    "    job_config = bigquery.LoadJobConfig(source_format=bigquery.SourceFormat.PARQUET, write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE)\n",
    "    with open(parquet_file, \"rb\") as source_file:\n",
    "        job = client.load_table_from_file(source_file, table_ref, job_config=job_config)\n",
    "\n",
    "    # Wait for the load job to complete\n",
    "    job.result()\n",
    "\n",
    "    # Download table schema\n",
    "    download_table_schema(table)\n",
    "\n",
    "    update_bigquery_schema_from_json(client, f\"dtsdatastore.CanvasDataPortal2.{table}\", get_latest_schema_file(table))\n",
    "\n",
    "    print(f\"Table {table} loaded to BigQuery.\")\n",
    "\n",
    "    # Clean up downloaded files\n",
    "    os.remove(parquet_file)\n",
    "    shutil.rmtree(os.path.dirname(parquet_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
